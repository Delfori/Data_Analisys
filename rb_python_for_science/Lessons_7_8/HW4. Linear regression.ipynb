{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c201591a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:20:56.413092Z",
     "start_time": "2021-10-08T14:20:56.409316Z"
    }
   },
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d8f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:20:56.413092Z",
     "start_time": "2021-10-08T14:20:56.409316Z"
    }
   },
   "source": [
    "В этом домашнем задании мы работаем с набором данных об уровне счастья в странах за 2019 год. Он доступен в репозитории или можно скачать с Kaggle [соревнования](https://www.kaggle.com/unsdsn/world-happiness?select=2019.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c5672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:24:45.084860Z",
     "start_time": "2021-10-08T14:24:45.081379Z"
    }
   },
   "source": [
    "Все импорты помещаем сверху, под этой клеткой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfeac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d612bd8a",
   "metadata": {},
   "source": [
    "1.Считайте данные с помощью pandas в переменную `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3aeea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b3cce20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T17:21:00.884611Z",
     "start_time": "2021-10-14T17:21:00.881566Z"
    }
   },
   "source": [
    "2.Выведите диаграмму рассеяния признаков `Score` и `GDP per capita` используя метод `regplot()` из `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a32b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe20c4f7",
   "metadata": {},
   "source": [
    "Мы будем моделировать эту зависимость. То есть независимой переменной является `GDP per capita`, зависимой `Score`. Судя по диаграмме рассеяния, зависимость между этими двумя переменными должна хорошо описываться линейной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2b15e",
   "metadata": {},
   "source": [
    "## Решение задачи линейной регрессии методом градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7382a",
   "metadata": {},
   "source": [
    "Обозначения:\n",
    "- `X` - матрица признаков\n",
    "- `y` - целевая переменная\n",
    "- `theta` - вектор параметров\n",
    "- `alpha` - темп обучения (learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0820ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:31:44.843127Z",
     "start_time": "2021-10-08T14:31:44.839958Z"
    }
   },
   "source": [
    "3.Реализуйте формулу предсказания линейной регрессии в методе `predict`. Метод возвращает предсказание. Напомню, что для каждого наблюдения из матрицы признаков предсказание находим с помощью следующей формулы:\n",
    "$$x \\in X, i \\in [1,m], j : \\\\ \\hat{y}_i = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n = \\theta^T x ,\\\\\n",
    "\\text{где m - количество наблюдений, } \\\\ \n",
    "\\text{n - количество признаков, } \\\\\n",
    "x_0 = 1 \\ \\text{для всех наблюдений}.\n",
    "$$\n",
    "\n",
    "Предсказания для всех наблюдений в матрице Х можем найти как умножение матрицы признаков на веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f34e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:30:30.020347Z",
     "start_time": "2021-10-08T14:30:30.017723Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    prediction = ...\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68bc0e",
   "metadata": {},
   "source": [
    "4.Дополните вычисление значения функции затрат, формула которой приведена в слайдах лекции о линейной регрессии (подсказка - формула такая же, как если бы мы считали среднеквадратичную ошибку).   \n",
    "Метод `cost()` принимает вектор параметров `theta`, матрицу наших признаков `X` и реальные значения  целевой переменной `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e63ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T20:45:54.974985Z",
     "start_time": "2021-10-08T20:45:54.972316Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost(y_true, y_estimate):\n",
    "    m = len(y)\n",
    "    cost_value = ... # ваш код тут\n",
    "    return cost_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64975088",
   "metadata": {},
   "source": [
    "5.Ознакомьтесь с реализацией метода `get_gradient()`, которая возвращает вектор частных производных функции затрат по каждому из параметров линейной регрессии.\n",
    "Дополните метод `gradient_descent()`, которые позволят реализовать  алгоритм градиетного спуска. В ходе градиентного спука мы обновляем параметры согласно формуле: \n",
    "$$\n",
    "\\text{для каждого} \\ j \\in [0, n]: \\quad \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta), \\\\ \n",
    "\\text{где n - количество признаков}\n",
    "$$\n",
    "    Метод градиентного спуска обновляет веса (модель обучается) пока они не перестанут меняться от итерации к итерации, то есть пока Эвклидово расстояние (обычное расстояние между веткорами как в школьной геометрии) между векторами весов за последние две итерации не будет меньше небольшой константы (обычно обозначается как $\\epsilon$ (эпсилон), мы установим $\\epsilon=10^{-6}$).\n",
    "\n",
    "В `gradient_descent()` заполните все места, где стоят троеточия. Используйте реализованные в предыдущих заданиях методы `cost()` и `predict()`, и конечно же Вам понадобится метод `get_gradient()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaba898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T18:18:37.374720Z",
     "start_time": "2022-01-30T18:18:37.349521Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradient(X, y, y_estimate):\n",
    "    error = y_estimate - y\n",
    "    gradient = (1.0 / len(y)) * X.T.dot(error)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062f8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T14:33:36.235226Z",
     "start_time": "2022-01-23T14:33:36.199550Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate, eps, max_iterations):\n",
    "    cost_history = []\n",
    "    theta_history = []\n",
    "    iterations = 1\n",
    "    while True:\n",
    "        y_estimate = ... # предсказание с текущими значениями весов\n",
    "        gradient = ... # значения частных производных функции затрат с текущими значениями весов\n",
    "        cost_value = ... # значение функции затрат при текущих весах\n",
    "        cost_history.append(cost_value)\n",
    "        new_theta = ...\n",
    "        theta_history.append(new_theta)\n",
    "        # Условие остановки, описанное в условии задания\n",
    "        if ... < eps:\n",
    "            print(\"Алгоритм сошёлся.\")\n",
    "            break\n",
    "            \n",
    "        # Второе условие остановки\n",
    "        if iterations >= max_iterations:\n",
    "            print(\"Достигнуто максимальное число итераций\")\n",
    "            break\n",
    "\n",
    "        # Выводим информацию каждые 100 итераций\n",
    "        if iterations % 100 == 0:\n",
    "            print (\"Итерация: %d - Ошибка на трейн данных: %.4f\" % (iterations, cost_value))\n",
    "\n",
    "        iterations += 1\n",
    "        theta = new_theta\n",
    "    return theta, cost_history, theta_history, iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefb83e",
   "metadata": {},
   "source": [
    "Подготовим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb2770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T19:28:00.717047Z",
     "start_time": "2021-10-10T19:28:00.714364Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['GDP per capita'].values.reshape(-1,1)\n",
    "y = df['Score'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb7483",
   "metadata": {},
   "source": [
    "6.Разделите `X` и `y` на `train` и `test` подвыборки в соотношении 80/20. Поскольку у нас мало данных, валидационную выборку выделять не будем. Запишите результаты в `X_train`, `y_train`, `X_test`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d3842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54c99e4",
   "metadata": {},
   "source": [
    "7.Реализуйте масштабирование признаков с использованием `MinMaxScaler`. Помните о том, как мы применяем масштабирование признаков на `train` и `test` выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f92029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832cd76a",
   "metadata": {},
   "source": [
    "8.Добавьте колонку из единичек в массивы `X_train`, `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722e7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf927241",
   "metadata": {},
   "source": [
    "9.Установите темп обучения равный 0.01, точность эпсилон равный $10^{-6}$, количество итераций равное 20000 и запустите градиентный спуск на тренировочных данных, передав все необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed756079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T20:20:00.992990Z",
     "start_time": "2021-10-08T20:20:00.989771Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = ...\n",
    "max_iterations = ...\n",
    "epsilon = ...\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "theta, cost_history, theta_history, iterations = gradient_descent(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763cd65b",
   "metadata": {},
   "source": [
    "10.Отобразите на линейном графике значения переменной `cost_history`. Используйте любую библиотеку для визуализации на ваш выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdacbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f25e7b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T14:56:41.741952Z",
     "start_time": "2021-10-08T14:56:41.738456Z"
    }
   },
   "source": [
    "Отобразите только первые 200 итераций. Похоже, после них модель мало обучается. Мы могли бы применить технику early stopping в данном случае и остановиться на некотором небольшом количестве итераций. Обычно эта техника применяется, чтоб збежать переобучения. При этом теряется немного точности на train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96588e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T18:20:36.325570Z",
     "start_time": "2022-01-30T18:20:36.209097Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b03a7de",
   "metadata": {},
   "source": [
    "Выведем полученные параметры и последнее значение функции затрат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b599fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T20:48:05.893974Z",
     "start_time": "2021-10-08T20:48:05.890650Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][-1],theta[1][-1]))\n",
    "print('Final cost/MSE:  {:0.3f}'.format(cost_history[-1]))\n",
    "print('Number of iterateions: {:d}'.format(iterations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b900aa2",
   "metadata": {},
   "source": [
    "11.Найдите прогнозы на `X_train_df`, `X_test_df` и посчитайте `mean_squared_error` ошибку прогнозов на обеих подвыборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c350ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5de21d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T15:02:52.150262Z",
     "start_time": "2021-10-08T15:02:52.146946Z"
    }
   },
   "source": [
    "12.Выведите диаграмму рассеяния признаков `Score` и `GDP per capita` и добавьте линию прогноза модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53e725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c55cead",
   "metadata": {},
   "source": [
    "13.Обучите линейную регрессию на наборе данных состоящем только из признака `GDP per capita`, но теперь используя LinearRegression из sklearn.   \n",
    "Подумайте, надо ли в sklearn модель подавать колонку из единичек, которую мы подавали в самописную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fd861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff8707d",
   "metadata": {},
   "source": [
    "Сравните ошибку на тестовой выборке линейной регрессии, написанной вами, и из sklearn. Есть ли разница в значениях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86662ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e8299b",
   "metadata": {},
   "source": [
    "14.Обучим линейную регрессию на большем количестве признаков и посмотрим, удастся ли улучшить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e10ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T16:54:08.159686Z",
     "start_time": "2021-10-14T16:54:08.152242Z"
    }
   },
   "source": [
    "14.1.Обучите линейную регрессию из sklearn используя в качестве набора признаков следующий: `GDP per capita`, `Social support`, `Healthy life expectancy`, `Freedom to make life choices`, `Generosity`, `Perceptions of corruption`\n",
    "\n",
    "Не забудьте:  \n",
    "1. Разделить на `train` и `test`.\n",
    "2. Нормировать каждую колонку данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69958ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d8e3625",
   "metadata": {},
   "source": [
    "14.2.Выведите ошибку прогноза на `train` и `test` выборках. Сравните с результатом, полученным при обучении на одном признаке. Изменились ли метрики?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95591a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b2b3fb",
   "metadata": {},
   "source": [
    "14.3.Выведите коэффициенты модели и определите, какие признаки имеют стоящие перед ними наибольшие коэффициенты по модулю (достаточно вывести названия признаков и коэффициенты в одном датафрейме)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649e634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21912671",
   "metadata": {},
   "source": [
    "15.Обучите модель полиномиальной регрессии со степенью 2 на тех же данных, что и в предыдущем пункте. Используйте в процессе обучения `PolynomialFeatures`. Исследуйте метрики качества на трейн и тест датасетах. Есть ли переобучение (overfit)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2432d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af1ffc17",
   "metadata": {},
   "source": [
    "16.Сделайте пайплайн с шагами `MinMaxScaler`, `PolynomialFeatures` и `ElasticNet`. Проведите поиск оптимальных гиперпараметров на тренировочном наборе данных используя `GridSearchCV`, метрика качества.   \n",
    "Какие риперпараметры искать выберите на своё усмотрение, к примеру, это могут быть параметры регуляризации `ElasticNet` или количество степеней в `PolynomialFeatures`.  \n",
    "Выведите значения найденных оптимальных гиперпараметров.  \n",
    "Лучшую модель из кросс валидации оцените на тестовом наборе данных.  \n",
    "\n",
    "\n",
    "Какая модель в домашнем задании дала лучшие значения среднеквадратичной ошибки на тестовых данных, лин. регрессия написанная самостоятельно, лин. регрессия из sklearn, полиномиальная регрессия со степенями признаков 2, модель найденная в результате поиска гиперпараметров?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b654ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
